{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coffea Processors\n",
    "Coffea relies mainly on [uproot](https://github.com/scikit-hep/uproot) to provide access to ROOT files for analysis.\n",
    "As a usual analysis will involve processing tens to thousands of files, totalling gigabytes to terabytes of data, there is a certain amount of work to be done to build a parallelized framework to process the data in a reasonable amount of time. \n",
    "\n",
    "Since the beginning a `coffea.processor` module was provided to encapsulate the core functionality of the analysis, which could be run locally or distributed via a number of Executors. This allowed users to worry just about the actual analysis code and not about how to implement efficient parallelization, assuming that the parallization is a trivial map-reduce operation (e.g. filling histograms and adding them together). This API ceased to exist for some time but we brought it back.\n",
    "\n",
    "In coffa 202x (CalVer), you also have the option of deeper integration with `dask` (via `dask_awkward` and `uproot.dask`), and whether an analysis is to be executed on local or distributed resources, a TaskGraph encapsulating the analysis is created in this case. We will demonstrate how to use callable code to build these TGs.\n",
    "\n",
    "We'll always be showcasing both ways of using coffea to write and execute your analyis\n",
    "\n",
    "Let's start by writing a simple processor class that reads some CMS open data and plots a dimuon mass spectrum.\n",
    "We'll start by copying the [ProcessorABC](https://coffea-hep.readthedocs.io/en/latest/api/coffea.processor.ProcessorABC.html#coffea.processor.ProcessorABC) skeleton and filling in some details:\n",
    "\n",
    " * Remove `flag`, as we won't use it\n",
    " * Adding a new histogram for $m_{\\mu \\mu}$\n",
    " * Building a [Candidate](https://coffea-hep.readthedocs.io/en/latest/api/coffea.nanoevents.methods.candidate.PtEtaPhiMCandidate.html#coffea.nanoevents.methods.candidate.PtEtaPhiMCandidate) record for muons, since we will read it with `BaseSchema` interpretation (the files used here could be read with `NanoAODSchema` but we want to show how to build vector objects from other TTree formats) \n",
    " * Calculating the dimuon invariant mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import awkward as ak\n",
    "import dask_awkward as dak\n",
    "from coffea import processor\n",
    "from coffea.nanoevents.methods import candidate\n",
    "import hist\n",
    "import hist.dask\n",
    "import dask\n",
    "\n",
    "class MyProcessor(processor.ProcessorABC):\n",
    "    def __init__(self, mode=\"virtual\"):\n",
    "        assert mode in [\"eager\", \"virtual\", \"dask\"]\n",
    "        self._mode = mode\n",
    "\n",
    "    def process(self, events):\n",
    "        dataset = events.metadata['dataset']\n",
    "        muons = ak.zip(\n",
    "            {\n",
    "                \"pt\": events.Muon_pt,\n",
    "                \"eta\": events.Muon_eta,\n",
    "                \"phi\": events.Muon_phi,\n",
    "                \"mass\": events.Muon_mass,\n",
    "                \"charge\": events.Muon_charge,\n",
    "            },\n",
    "            with_name=\"PtEtaPhiMCandidate\",\n",
    "            behavior=candidate.behavior,\n",
    "        )\n",
    "\n",
    "        if self._mode == \"dask\":\n",
    "            hist_class = hist.dask.Hist\n",
    "        else:\n",
    "            hist_class = hist.Hist\n",
    "        h_mass = (\n",
    "            hist_class.new\n",
    "            .StrCat([\"opposite\", \"same\"], name=\"sign\")\n",
    "            .Log(1000, 0.2, 200., name=\"mass\", label=r\"$m_{\\mu\\mu}$ [GeV]\")\n",
    "            .Int64()\n",
    "        )\n",
    "\n",
    "        cut = (ak.num(muons) == 2) & (ak.sum(muons.charge, axis=1) == 0)\n",
    "        # add first and second muon in every event together\n",
    "        dimuon = muons[cut][:, 0] + muons[cut][:, 1]\n",
    "        h_mass.fill(sign=\"opposite\", mass=dimuon.mass)\n",
    "\n",
    "        cut = (ak.num(muons) == 2) & (ak.sum(muons.charge, axis=1) != 0)\n",
    "        dimuon = muons[cut][:, 0] + muons[cut][:, 1]\n",
    "        h_mass.fill(sign=\"same\", mass=dimuon.mass)\n",
    "\n",
    "        if self._mode == \"dask\":\n",
    "            return {\n",
    "                    \"entries\": ak.num(events, axis=0),\n",
    "                    \"mass\": h_mass,\n",
    "            }\n",
    "        else:    \n",
    "            return {\n",
    "                dataset: {\n",
    "                    \"entries\": len(events),\n",
    "                    \"mass\": h_mass,\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    def postprocess(self, accumulator):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we were to just use bare uproot to execute this processor, we could do that with the following example, which:\n",
    "\n",
    " * Opens a CMS open data file\n",
    " * Creates a NanoEvents object using `BaseSchema` (roughly equivalent to the output of reading with plain `uproot`)\n",
    " * Creates a `MyProcessor` instance\n",
    " * Runs the `process()` function, which returns our accumulators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffea.nanoevents import NanoEventsFactory, BaseSchema\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"root://xcache//store/user/ncsmith/opendata_mirror/Run2012B_DoubleMuParked.root\"\n",
    "access_log = []\n",
    "events = NanoEventsFactory.from_root(\n",
    "    {filename: \"Events\"},\n",
    "    entry_stop=500_000,\n",
    "    metadata={\"dataset\": \"DoubleMuon\"},\n",
    "    schemaclass=BaseSchema,\n",
    "    mode=\"virtual\",\n",
    "    access_log=access_log,\n",
    ").events()\n",
    "p = MyProcessor(\"virtual\")\n",
    "out = p.process(events)\n",
    "out, access_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "out = p.process(events)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "out[\"DoubleMuon\"][\"mass\"].plot1d(ax=ax)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend(title=\"Dimuon charge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filename = \"root://xcache//store/user/ncsmith/opendata_mirror/Run2012B_DoubleMuParked.root\"\n",
    "events = NanoEventsFactory.from_root(\n",
    "    {filename: {\"object_path\": \"Events\", \"steps\": [[0, 500_000]]}},\n",
    "    metadata={\"dataset\": \"DoubleMuon\"},\n",
    "    schemaclass=BaseSchema,\n",
    "    mode=\"dask\",\n",
    ").events()\n",
    "p = MyProcessor(\"dask\")\n",
    "taskgraph = p.process(events)\n",
    "taskgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dask.visualize(taskgraph, rankdir=\"LR\", optimize_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dask.visualize(taskgraph, rankdir=\"LR\", optimize_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "(out,)= dask.compute(taskgraph)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dak.necessary_columns(taskgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "out[\"mass\"].plot1d(ax=ax)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend(title=\"Dimuon charge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filesets\n",
    "We'll need to construct a fileset to run over\n",
    "\n",
    "## Users without access\n",
    "Uncomment the `eospublic` files in the following dictionary and comment out the `xcache` files, such that you still have one file per dataset (`DoubleMuon` and `ZZ to 4mu`), these should be reachable from anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_fileset = {\n",
    "    \"DoubleMuon\": {\n",
    "        \"files\": {\n",
    "            \"root://xcache//store/user/ncsmith/opendata_mirror/Run2012B_DoubleMuParked.root\": \"Events\",\n",
    "            #\"root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod/Run2012B_DoubleMuParked.root\": \"Events\",\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"is_mc\": False,\n",
    "        },\n",
    "    },\n",
    "    \"ZZ to 4mu\": {\n",
    "        \"files\": {\n",
    "            \"root://xcache//store/user/ncsmith/opendata_mirror/ZZTo4mu.root\": \"Events\",\n",
    "            #\"root://eospublic.cern.ch//eos/root-eos/cms_opendata_2012_nanoaod/ZZTo4mu.root\": \"Events\",\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"is_mc\": True,\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing with Virtual mode\n",
    "\n",
    "Preprocessing is hidden inside this interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "iterative_run = processor.Runner(\n",
    "    executor = processor.IterativeExecutor(compression=None),\n",
    "    schema=BaseSchema,\n",
    "    maxchunks=3,\n",
    "    savemetrics=True,\n",
    ")\n",
    "\n",
    "out, metrics = iterative_run(\n",
    "    initial_fileset,\n",
    "    processor_instance=MyProcessor(\"virtual\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "out[\"DoubleMuon\"][\"mass\"].plot1d(ax=ax)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend(title=\"Dimuon charge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to use more than a single core on our machine, we simply change `IterativeExecutor` for `FuturesExecutor`, which uses the python `concurrent.futures` standard library. We can then set the most interesting argument to the `FuturesExecutor`: the number of cores to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "futures_run = processor.Runner(\n",
    "    executor = processor.FuturesExecutor(workers=4, compression=None),\n",
    "    schema=BaseSchema,\n",
    "    savemetrics=True,\n",
    ")\n",
    "\n",
    "out, metrics = futures_run(\n",
    "    initial_fileset,\n",
    "    processor_instance=MyProcessor(\"virtual\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "out[\"DoubleMuon\"][\"mass\"].plot1d(ax=ax)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend(title=\"Dimuon charge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing with Dask mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "There are dataset discovery tools inside of coffea to help construct such datasets. Those will not be demonstrated here. For now, we'll take the above `initial_fileset` and preprocess it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from coffea.dataset_tools import apply_to_fileset, max_chunks, max_files, preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_available, preprocessed_total = preprocess(\n",
    "        initial_fileset,\n",
    "        step_size=100_000,\n",
    "        align_clusters=False,\n",
    "        skip_bad_files=True,\n",
    "        recalculate_steps=False,\n",
    "        files_per_batch=1,\n",
    "        file_exceptions=(OSError,),\n",
    "        save_form=False,\n",
    "        uproot_options={},\n",
    "        step_size_safety_factor=0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessed fileset\n",
    "Lets have a look at the contents of the preprocessed_available part of the fileset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving a preprocessed fileset\n",
    "We can use the gzip, pickle, and json modules/libraries to both save and reload datasets directly. We'll do this short example below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gzip, pickle, json\n",
    "output_file = \"example_fileset\"\n",
    "with gzip.open(f\"{output_file}_available.json.gz\", \"wt\") as file:\n",
    "    json.dump(preprocessed_available, file, indent=2)\n",
    "    print(f\"Saved available fileset chunks to {output_file}_available.json.gz\")\n",
    "with gzip.open(f\"{output_file}_all.json.gz\", \"wt\") as file:\n",
    "    json.dump(preprocessed_total, file, indent=2)\n",
    "    print(f\"Saved complete fileset chunks to {output_file}_all.json.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could then reload these filesets and quickly pick up where we left off. Often we'll want to preprocess again \"soon\" before analyzing data because this will let us catch which files are accessible now and which are not. The saved filesets may be useful for tracking, and we may have enough stability to reuse it for some period of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with gzip.open(f\"{output_file}_available.json.gz\", \"rt\") as file:\n",
    "    reloaded_available = json.load(file)\n",
    "with gzip.open(f\"{output_file}_all.json.gz\", \"rt\") as file:\n",
    "    reloaded_all = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Slicing chunks and files\n",
    "Given this preprocessed fileset, we can test our processor on just a few chunks of a handful of files. To do this, we use the max_files and max_chunks functions from the dataset tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preprocessed_files = max_files(preprocessed_available, 1)\n",
    "test_preprocessed = max_chunks(test_preprocessed_files, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "small_tg, small_rep = apply_to_fileset(data_manipulation=MyProcessor(\"dask\"),\n",
    "                            fileset=test_preprocessed,\n",
    "                            schemaclass=BaseSchema,\n",
    "                            uproot_options={\"allow_read_errors_with_report\": (OSError, ValueError)},\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dask.visualize(small_tg, optimize_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "small_computed, small_rep_computed = dask.compute(small_tg, small_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "small_rep_computed['DoubleMuon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "small_computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "small_computed[\"DoubleMuon\"][\"mass\"].plot1d(ax=ax)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend(title=\"Dimuon charge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_tg, rep = apply_to_fileset(data_manipulation=MyProcessor(\"dask\"),\n",
    "                            fileset=preprocessed_available,\n",
    "                            schemaclass=BaseSchema,\n",
    "                            uproot_options={\"allow_read_errors_with_report\": (OSError, ValueError)},\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "out, rep = dask.compute(full_tg, rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "out[\"DoubleMuon\"][\"mass\"].plot1d(ax=ax)\n",
    "ax.set_xscale(\"log\")\n",
    "ax.legend(title=\"Dimuon charge\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
